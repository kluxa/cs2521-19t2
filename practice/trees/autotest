#!/bin/bash
# Autotests exercises

COMMON_DIR="common/"
EXERCISES_DIR="exercises/"
SOLUTIONS_DIR="solutions/"
TEST_BIN_DIR="testbin/"
TEST_DRIVERS_DIR="testDrivers/"
TEST_DATA_DIR="tests/"

usage()
{
	echo "Usage: $0 [OPTION]... <exercise>..."
	echo "Options:"
	echo "    -s    autotests the solution instead of your code"
	echo "    -a    tests all exercises"
	exit 1
}

setup_testbin_dir()
{
	if [ ! -d "$TEST_BIN_DIR" ]
	then
		mkdir "$TEST_BIN_DIR"
	fi
}

check_solutions_exist()
{
	if [ ! -d "$SOLUTIONS_DIR" ]
	then
		echo "$0: No solutions available"
		exit 1
	fi
}

# $1: exercise name
# $2: source directory
compile_and_test()
{
	check_exercise_exists "$1"
	if [ "$2" = "$SOLUTIONS_DIR" ]
	then
		check_exercise_solution_exists "$1"
	fi
	check_test_driver_exists "$1"
	check_tests_exist "$1"
	
	printf "\033[0;1m===> $1 <===\033[0m\n"
	compile_test_driver "$1" "$2"
	run_tests "$1"
	echo ""
}

# $1: exercise name
check_exercise_exists()
{
	if [ ! -e "$EXERCISES_DIR/$1.c" ]
	then
		echo "$0: No exercise named '$1'"
		exit 1
	fi
}

# $1: exercise name
check_tests_exist()
{
	if [ ! -d "$TEST_DATA_DIR/$1" ]
	then
		echo "No tests available for $1"
		exit 1
	fi
	
	if [ -z "$(ls -A $TEST_DATA_DIR/$1)" ]
	then
		echo "No tests available for $1"
		exit 1
	fi
}

# $1: exercise name
check_exercise_solution_exists()
{	
	if [ ! -e "$SOLUTIONS_DIR/$1.c" ]
	then
		echo "$0: No solutions available for $1"
		exit 1
	fi
}

# $1: exercise name
# $2: source directory
compile_test_driver()
{
	echo "Compiling..."
	gcc -Wall -Werror -std=gnu99 -g -o "$TEST_BIN_DIR/test${1^}" "$COMMON_DIR"/*.[co] "$TEST_DRIVERS_DIR/test${1^}.c" "$2/$1.c" || exit 1
	echo ""
}

# $1: exercise name
check_test_driver_exists()
{
	if [ ! -e "$TEST_DRIVERS_DIR/test${1^}.c" ]
	then
		echo "$0: No test driver available for $1"
		exit 1
	fi
}

# $1: exercise name
run_tests()
{
	test_bin="$TEST_BIN_DIR/test${1^}"
	
	ntests=0
	npassed=0
	nfailed=0
	for test_data_file in "$TEST_DATA_DIR/$1/"??
	do
		ntests=$(expr $ntests + 1)
		
		echo "Test $ntests"
		"$test_bin" < "$test_data_file" > "$test_data_file.out"
		
		if diff "$test_data_file.out" "$test_data_file.exp" > /dev/null
		then
			npassed=$(expr $npassed + 1)
			printf "\033[32mTest passed\033[0m\n"
			echo ""
		else
			nfailed=$(expr $nfailed + 1)
			printf "\033[31mTest failed\033[0m\n"
			printf "\033[33mCompare your program's output and the expected output in $test_data_file.out and $test_data_file.exp, and check the input file in $test_data_file\n\033[0m"
			echo ""
		fi
	done
	
	show_test_summary $npassed $nfailed
}

# $1: number of tests passed
# $2: number of tests failed
show_test_summary()
{
	printf "\033[32;1m$1 tests passed \033[31;1m$2 tests failed\033[0m\n"
	if [ $2 -eq 0 ]
	then
		echo "All tests passed. You are awesome!"
	fi
}

########################################################################
# process args

if [ $# -eq 0 ]
then
	usage
fi

i=0
source_dir="$EXERCISES_DIR"
test_all=0

for arg in "$@"
do
	if [ $arg = "-s" ]
	then
		source_dir="$SOLUTIONS_DIR"
	elif [ $arg = "-a" ]
	then
		test_all=1
	else
		EXERCISES[$i]="$arg"
		i=$(expr $i + 1)
	fi
done

cd $(dirname $0)

if [ "$source_dir" = "$SOLUTIONS_DIR" ]
then
	check_solutions_exist
fi

setup_testbin_dir

########################################################################
# run subroutines

if [ $test_all -eq 1 ]
then
	for exercise_file in "$source_dir"/*.c
	do
		exercise_name=$(basename "$exercise_file" .c)
		compile_and_test "$exercise_name" "$source_dir"
	done
else
	for exercise_name in "${EXERCISES[@]}"
	do
		compile_and_test "$exercise_name" "$source_dir"
	done
fi

